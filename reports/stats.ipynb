{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We start by importing our basic modules and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Country_x', 'Country Code', 'Region', 'Poverty Level', 'Capital City',\n",
       "       'Lat/Long', 'Poverty Value (1-4)', 'Country name', 'Year',\n",
       "       'Life Ladder', 'Log GDP per capita', 'Social support',\n",
       "       'Healthy life expectancy at birth', 'Freedom to make life choices',\n",
       "       'Generosity', 'Perceptions of corruption', 'Positive affect',\n",
       "       'Negative affect', 'Confidence in national government',\n",
       "       'Democratic Quality', 'Delivery Quality',\n",
       "       'Standard deviation of ladder by country-year',\n",
       "       'Standard deviation/Mean of ladder by country-year',\n",
       "       'GINI index (World Bank estimate)',\n",
       "       'GINI index (World Bank estimate), average 2000-16',\n",
       "       'gini of household income reported in Gallup, by wp5-year',\n",
       "       'Most people can be trusted, Gallup',\n",
       "       'Most people can be trusted, WVS round 1981-1984',\n",
       "       'Most people can be trusted, WVS round 1989-1993',\n",
       "       'Most people can be trusted, WVS round 1994-1998',\n",
       "       'Most people can be trusted, WVS round 1999-2004',\n",
       "       'Most people can be trusted, WVS round 2005-2009',\n",
       "       'Most people can be trusted, WVS round 2010-2014', 'Country ID',\n",
       "       'Revenue ($M)', 'Country_y', 'Population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We start by importing our basic modules and data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = os.path.join('..','data','cleanData','almost_complete.csv')\n",
    "data = pd.read_csv(data_path)\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we do any analysis, we want to check if our data makes sense. While our data has been cleaned and should be compelete, we want to check if there are any outliers in our data. We will do this for all columns we will be analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_x</th>\n",
       "      <th>Year</th>\n",
       "      <th>Life Ladder</th>\n",
       "      <th>Outlier type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Country_x, Year, Life Ladder, Outlier type]\n",
       "Index: []"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check for any happiness outliers\n",
    "happiness = data[['Country_x', 'Year', 'Life Ladder']]\n",
    "happiness = happiness.dropna()\n",
    "#calculate our upper and lower bounds as per usual. Standard stuff\n",
    "q1 = np.percentile(happiness['Life Ladder'], 25)\n",
    "q3 = np.percentile(happiness['Life Ladder'], 75)\n",
    "IQR = q3-q1\n",
    "lower_bound = q1 - 1.5*IQR\n",
    "upper_bound = q3 + 1.5*IQR\n",
    "#now we create an upper and lower data frame and then combine them, noting whether they are upper or lower outliers\n",
    "test_upper_h = happiness.loc[(happiness['Life Ladder'] > upper_bound)]\n",
    "test_upper_h['Outlier type'] = \"Upper\"\n",
    "test_lower_h = happiness.loc[(happiness['Life Ladder'] < lower_bound)]\n",
    "test_lower_h['Outlier type'] = \"Lower\"\n",
    "outliers = pd.concat([test_lower_h, test_upper_h])\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_x</th>\n",
       "      <th>Year</th>\n",
       "      <th>Freedom to make life choices</th>\n",
       "      <th>Outlier type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>Burundi</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.260069</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>2009.0</td>\n",
       "      <td>0.257534</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>356</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0.281458</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>640</td>\n",
       "      <td>Haiti</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>0.303540</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>707</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>0.314565</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1442</td>\n",
       "      <td>Chad</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>0.306132</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1443</td>\n",
       "      <td>Chad</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>0.294612</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1456</td>\n",
       "      <td>Togo</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0.286814</td>\n",
       "      <td>Lower</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Country_x    Year  Freedom to make life choices  \\\n",
       "99                   Burundi  2008.0                      0.260069   \n",
       "171   Bosnia and Herzegovina  2009.0                      0.257534   \n",
       "356                     Cuba  2006.0                      0.281458   \n",
       "640                    Haiti  2016.0                      0.303540   \n",
       "707                     Iraq  2012.0                      0.314565   \n",
       "1442                    Chad  2006.0                      0.306132   \n",
       "1443                    Chad  2007.0                      0.294612   \n",
       "1456                    Togo  2008.0                      0.286814   \n",
       "\n",
       "     Outlier type  \n",
       "99          Lower  \n",
       "171         Lower  \n",
       "356         Lower  \n",
       "640         Lower  \n",
       "707         Lower  \n",
       "1442        Lower  \n",
       "1443        Lower  \n",
       "1456        Lower  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check for any freedom outliers\n",
    "freedom = data[['Country_x', 'Year', 'Freedom to make life choices']]\n",
    "freedom = freedom.dropna()\n",
    "#calculate our upper and lower bounds as per usual. Standard stuff\n",
    "q1 = np.percentile(freedom['Freedom to make life choices'], 25)\n",
    "q3 = np.percentile(freedom['Freedom to make life choices'], 75)\n",
    "IQR = q3-q1\n",
    "lower_bound = q1 - 1.5*IQR\n",
    "upper_bound = q3 + 1.5*IQR\n",
    "#now we create an upper and lower data frame and then combine them, noting whether they are upper or lower outliers\n",
    "test_upper_f = freedom.loc[(freedom['Freedom to make life choices'] > upper_bound)]\n",
    "test_upper_f['Outlier type'] = \"Upper\"\n",
    "test_lower_f = freedom.loc[(freedom['Freedom to make life choices'] < lower_bound)]\n",
    "test_lower_f['Outlier type'] = \"Lower\"\n",
    "outliers = pd.concat([test_lower_f, test_upper_f])\n",
    "outliers\n",
    "#we ignore the warning here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_x</th>\n",
       "      <th>Year</th>\n",
       "      <th>Log GDP per capita</th>\n",
       "      <th>Outlier type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Country_x, Year, Log GDP per capita, Outlier type]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check for any Log GDP per capita outliers\n",
    "LGDPperC = data[['Country_x', 'Year', 'Log GDP per capita']]\n",
    "LGDPperC = LGDPperC.dropna()\n",
    "#calculate our upper and lower bounds as per usual. Standard stuff\n",
    "q1 = np.percentile(LGDPperC['Log GDP per capita'], 25)\n",
    "q3 = np.percentile(LGDPperC['Log GDP per capita'], 75)\n",
    "IQR = q3-q1\n",
    "lower_bound = q1 - 1.5*IQR\n",
    "upper_bound = q3 + 1.5*IQR\n",
    "#now we create an upper and lower data frame and then combine them, noting whether they are upper or lower outliers\n",
    "test_upper_g = LGDPperC.loc[(LGDPperC['Log GDP per capita'] > upper_bound)]\n",
    "test_upper_g['Outlier type'] = \"Upper\"\n",
    "test_lower_g = LGDPperC.loc[(LGDPperC['Log GDP per capita'] < lower_bound)]\n",
    "test_lower_g['Outlier type'] = \"Lower\"\n",
    "outliers = pd.concat([test_lower_g, test_upper_g])\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maste\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "C:\\Users\\maste\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country_x</th>\n",
       "      <th>Year</th>\n",
       "      <th>Revenue per capita</th>\n",
       "      <th>Outlier type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>132.780013</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>Austria</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>140.345732</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>252</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>139.642887</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>253</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>144.408846</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>260</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>203.403655</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>261</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>210.851743</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>140.028527</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>Germany</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>161.963366</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>413</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>158.544974</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>414</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>167.340514</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>165.528457</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>537</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>171.595667</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>718</td>\n",
       "      <td>Iceland</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>145.266815</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>839</td>\n",
       "      <td>Korea, Rep.</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>169.929952</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>840</td>\n",
       "      <td>Korea, Rep.</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>177.866877</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1133</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>151.713932</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1134</td>\n",
       "      <td>Netherlands</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>161.620755</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1141</td>\n",
       "      <td>Norway</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>255.014131</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1142</td>\n",
       "      <td>Norway</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>266.158043</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>138.752295</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1351</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>154.994264</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1431</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>246.373771</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1432</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>256.731802</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1589</td>\n",
       "      <td>United States</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>169.787999</td>\n",
       "      <td>Upper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Country_x    Year  Revenue per capita Outlier type\n",
       "84           Austria  2017.0          132.780013        Upper\n",
       "85           Austria  2018.0          140.345732        Upper\n",
       "252           Canada  2017.0          139.642887        Upper\n",
       "253           Canada  2018.0          144.408846        Upper\n",
       "260      Switzerland  2017.0          203.403655        Upper\n",
       "261      Switzerland  2018.0          210.851743        Upper\n",
       "396          Germany  2017.0          140.028527        Upper\n",
       "397          Germany  2018.0          161.963366        Upper\n",
       "413          Denmark  2017.0          158.544974        Upper\n",
       "414          Denmark  2018.0          167.340514        Upper\n",
       "536   United Kingdom  2017.0          165.528457        Upper\n",
       "537   United Kingdom  2018.0          171.595667        Upper\n",
       "718          Iceland  2017.0          145.266815        Upper\n",
       "839      Korea, Rep.  2017.0          169.929952        Upper\n",
       "840      Korea, Rep.  2018.0          177.866877        Upper\n",
       "1133     Netherlands  2017.0          151.713932        Upper\n",
       "1134     Netherlands  2018.0          161.620755        Upper\n",
       "1141          Norway  2017.0          255.014131        Upper\n",
       "1142          Norway  2018.0          266.158043        Upper\n",
       "1350       Singapore  2017.0          138.752295        Upper\n",
       "1351       Singapore  2018.0          154.994264        Upper\n",
       "1431          Sweden  2017.0          246.373771        Upper\n",
       "1432          Sweden  2018.0          256.731802        Upper\n",
       "1589   United States  2018.0          169.787999        Upper"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we check for any Electronic Sales Revenue per capita outliers\n",
    "ER = data[['Country_x', 'Year', 'Revenue ($M)', 'Population']]\n",
    "ER = ER.dropna()\n",
    "ERperC = ER[['Country_x', 'Year']]\n",
    "ERperC['Revenue per capita'] = ER['Revenue ($M)']*1000000/ER['Population']\n",
    "\n",
    "#calculate our upper and lower bounds as per usual. Standard stuff\n",
    "q1 = np.percentile(ERperC['Revenue per capita'], 25)\n",
    "q3 = np.percentile(ERperC['Revenue per capita'], 75)\n",
    "IQR = q3-q1\n",
    "lower_bound = q1 - 1.5*IQR\n",
    "upper_bound = q3 + 1.5*IQR\n",
    "#now we create an upper and lower data frame and then combine them, noting whether they are upper or lower outliers\n",
    "test_upper_er = ERperC.loc[(ERperC['Revenue per capita'] > upper_bound)]\n",
    "test_upper_er['Outlier type'] = \"Upper\"\n",
    "test_lower_er = ERperC.loc[(ERperC['Revenue per capita'] < lower_bound)]\n",
    "test_lower_er['Outlier type'] = \"Lower\"\n",
    "outliers = pd.concat([test_lower_er, test_upper_er])\n",
    "outliers\n",
    "#ignore warnings again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We've found a number of outliers for freedom and Electronic Revenue Data, however we won't get rid of these from our analysis as there's nothing really wrong with these values and they could have genuine ramifications that we might be interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, before we do any statistical analysis such as t-tests, does our data match the required conditions for running those? We'll be running Welch's t-tests so we don't need to worry about variances, and while we don't know if our data is normalized, we actually don't need to worry about it in this case. Because our sample size is large relative to our population, we can consider the Central Limit Theorem and normality of our sample sums follows trivially, despite a possible lack of normality in our original values. Thus, we can continue and carry out our analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We want to see whether GDP or freedom correlates better with happiness.\n",
    "So we do linear regression and find p-values for happiness vs Log GDP per capita and happiness vs freedom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiness vs Log GDP per capita:\n",
      "slope = 0.822772548902285\n",
      "intercept = 4.742404978293741\n",
      "r = 0.7792201240864797\n",
      "p = 0.0\n",
      "standard error = 0.016228115581241473\n"
     ]
    }
   ],
   "source": [
    "#happiness vs Log GDP per capita\n",
    "hapvsGDP = data[['Life Ladder', 'Log GDP per capita']]\n",
    "hapvsGDP = hapvsGDP.dropna(how = 'any')\n",
    "happiness = hapvsGDP['Life Ladder']\n",
    "LGDPperC = hapvsGDP['Log GDP per capita']\n",
    "#Do some linear regression to get p values (as t-test is included in it)\n",
    "(slope, intercept, r, p, stderr) = stats.linregress(happiness, LGDPperC)\n",
    "print(\"Happiness vs Log GDP per capita:\")\n",
    "print(\"slope = \" + str(slope))\n",
    "print(\"intercept = \" + str(intercept))\n",
    "print(\"r = \" + str(r))\n",
    "print(\"p = \" + str(p))\n",
    "print(\"standard error = \" + str(stderr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happiness vs Freedom:\n",
      "slope = 0.0672601670844012\n",
      "intercept = 0.36842487510627075\n",
      "r = 0.5243317769244311\n",
      "p = 6.758162274825783e-118\n",
      "standard error = 0.002682571592781182\n"
     ]
    }
   ],
   "source": [
    "#happiness vs freedom\n",
    "hapvsFree = data[['Life Ladder', 'Freedom to make life choices']]\n",
    "hapvsFree = hapvsFree.dropna(how = 'any')\n",
    "happiness = hapvsFree['Life Ladder']\n",
    "freedom = hapvsFree['Freedom to make life choices']\n",
    "#do linear regression\n",
    "(slope, intercept, r, p, stderr) = stats.linregress(happiness, freedom)\n",
    "print(\"Happiness vs Freedom:\")\n",
    "print(\"slope = \" + str(slope))\n",
    "print(\"intercept = \" + str(intercept))\n",
    "print(\"r = \" + str(r))\n",
    "print(\"p = \" + str(p))\n",
    "print(\"standard error = \" + str(stderr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From this we can conclude that while both freedom and Log GDP per capita correlate incredibly closely with happiness, Log GDP per capita correlates a little more closely than freedom does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freedom vs Log GDP per capita:\n",
      "slope = 2.9456891299620356\n",
      "intercept = 7.0538711175660485\n",
      "r = 0.35885506329301525\n",
      "p = 6.671643451725446e-51\n",
      "standard error = 0.189542447678058\n"
     ]
    }
   ],
   "source": [
    "#for funsies, I'll go ahead and see how well GDP and freedom correlate\n",
    "#happiness vs freedom\n",
    "FreevsGDP = data[['Freedom to make life choices', 'Log GDP per capita']]\n",
    "FreevsGDP = FreevsGDP.dropna(how = 'any')\n",
    "freedom = FreevsGDP['Freedom to make life choices']\n",
    "LGDPperC = FreevsGDP['Log GDP per capita']\n",
    "#do linear regression\n",
    "(slope, intercept, r, p, stderr) = stats.linregress(freedom, LGDPperC)\n",
    "print(\"Freedom vs Log GDP per capita:\")\n",
    "print(\"slope = \" + str(slope))\n",
    "print(\"intercept = \" + str(intercept))\n",
    "print(\"r = \" + str(r))\n",
    "print(\"p = \" + str(p))\n",
    "print(\"standard error = \" + str(stderr))\n",
    "#we see that they correlate very closely, but not as well as the above combinations do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we want to see whether Electronic Revenue per capita correlates well with happiness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.65289979766012\n",
      "-160.5056560453105\n",
      "0.704240919583214\n",
      "1.6325007046398953e-39\n",
      "2.25968488188548\n"
     ]
    }
   ],
   "source": [
    "#happiness vs Electronic Revenue per capita\n",
    "hapvsERperC = data[['Life Ladder', 'Revenue ($M)', 'Population']]\n",
    "hapvsERperC = hapvsERperC.dropna(how = 'any')\n",
    "happiness = hapvsERperC['Life Ladder']\n",
    "#we calculate electronic revenue per capita and change from in $M to $ so our numbers make more sense\n",
    "ERperC = hapvsERperC['Revenue ($M)']*1000000/hapvsERperC['Population']\n",
    "#do our linear regression for the t-test\n",
    "(slope, intercept, r, p, stderr) = stats.linregress(happiness, ERperC)\n",
    "print(slope)\n",
    "print(intercept)\n",
    "print(r)\n",
    "print(p)\n",
    "print(stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We see that there is a strong correlation between Happiness and Electronic Revenue per capita, although not as strong a correlation as there was for Freedom or Log GDP per capita"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
